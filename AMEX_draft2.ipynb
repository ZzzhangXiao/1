{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import keras\n",
    "from pandas.plotting import scatter_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import make_pipeline as make_imb_pipeline\n",
    "from imblearn.under_sampling import RepeatedEditedNearestNeighbours\n",
    "from imblearn.under_sampling import EditedNearestNeighbours\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "from pympler import tracker\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.16.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ind_recommended</th>\n",
       "      <th>activation</th>\n",
       "      <th>customer_digital_activity_04</th>\n",
       "      <th>customer_spend_01</th>\n",
       "      <th>customer_industry_spend_01</th>\n",
       "      <th>customer_industry_spend_02</th>\n",
       "      <th>customer_industry_spend_03</th>\n",
       "      <th>customer_industry_spend_04</th>\n",
       "      <th>customer_industry_spend_05</th>\n",
       "      <th>customer_spend_02</th>\n",
       "      <th>...</th>\n",
       "      <th>merchant_spend_09</th>\n",
       "      <th>merchant_profile_03</th>\n",
       "      <th>customer_digital_activity_01</th>\n",
       "      <th>merchant_spend_10</th>\n",
       "      <th>customer_profile_03</th>\n",
       "      <th>customer_digital_activity_02</th>\n",
       "      <th>customer_profile_04</th>\n",
       "      <th>distance_05</th>\n",
       "      <th>customer</th>\n",
       "      <th>merchant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>107.215862</td>\n",
       "      <td>26.686594</td>\n",
       "      <td>74.0</td>\n",
       "      <td>3682.75</td>\n",
       "      <td>138.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>49466.0</td>\n",
       "      <td>65923.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.180</td>\n",
       "      <td>58.434969</td>\n",
       "      <td>32.500000</td>\n",
       "      <td>86.0</td>\n",
       "      <td>15.856826</td>\n",
       "      <td>168972</td>\n",
       "      <td>152285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.552000</td>\n",
       "      <td>50.928261</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1171.35</td>\n",
       "      <td>23.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3638.0</td>\n",
       "      <td>7801.0</td>\n",
       "      <td>0.419355</td>\n",
       "      <td>28.465</td>\n",
       "      <td>5.392089</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>125.0</td>\n",
       "      <td>6.998555</td>\n",
       "      <td>212404</td>\n",
       "      <td>39032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.623103</td>\n",
       "      <td>48.837872</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2295.38</td>\n",
       "      <td>47.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3912.0</td>\n",
       "      <td>12868.0</td>\n",
       "      <td>0.836364</td>\n",
       "      <td>421.500</td>\n",
       "      <td>33.780445</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>180.0</td>\n",
       "      <td>1.753009</td>\n",
       "      <td>225178</td>\n",
       "      <td>7439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>112.277391</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>28919.0</td>\n",
       "      <td>23553.0</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>50.000</td>\n",
       "      <td>37.340085</td>\n",
       "      <td>28.666667</td>\n",
       "      <td>134.0</td>\n",
       "      <td>9.000063</td>\n",
       "      <td>183948</td>\n",
       "      <td>485069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>448.427273</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1086.0</td>\n",
       "      <td>308.0</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>69.509</td>\n",
       "      <td>77.794164</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>114.0</td>\n",
       "      <td>1.767939</td>\n",
       "      <td>210107</td>\n",
       "      <td>536004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ind_recommended  activation  customer_digital_activity_04  \\\n",
       "0                0           0                           NaN   \n",
       "1                0           0                           NaN   \n",
       "2                0           0                           NaN   \n",
       "3                0           0                           NaN   \n",
       "4                1           0                           NaN   \n",
       "\n",
       "   customer_spend_01  customer_industry_spend_01  customer_industry_spend_02  \\\n",
       "0         107.215862                   26.686594                        74.0   \n",
       "1          35.552000                   50.928261                         3.0   \n",
       "2          31.623103                   48.837872                        19.0   \n",
       "3         112.277391                         NaN                         NaN   \n",
       "4         448.427273                         NaN                         NaN   \n",
       "\n",
       "   customer_industry_spend_03  customer_industry_spend_04  \\\n",
       "0                     3682.75                       138.0   \n",
       "1                     1171.35                        23.0   \n",
       "2                     2295.38                        47.0   \n",
       "3                         NaN                         NaN   \n",
       "4                         NaN                         NaN   \n",
       "\n",
       "   customer_industry_spend_05  customer_spend_02  ...  merchant_spend_09  \\\n",
       "0                       111.0               14.0  ...            49466.0   \n",
       "1                        17.0                2.0  ...             3638.0   \n",
       "2                        42.0               11.0  ...             3912.0   \n",
       "3                         NaN               16.0  ...            28919.0   \n",
       "4                         NaN                5.0  ...             1086.0   \n",
       "\n",
       "   merchant_profile_03  customer_digital_activity_01  merchant_spend_10  \\\n",
       "0              65923.0                      0.000000             29.180   \n",
       "1               7801.0                      0.419355             28.465   \n",
       "2              12868.0                      0.836364            421.500   \n",
       "3              23553.0                      0.952381             50.000   \n",
       "4                308.0                      0.754386             69.509   \n",
       "\n",
       "   customer_profile_03  customer_digital_activity_02  customer_profile_04  \\\n",
       "0            58.434969                     32.500000                 86.0   \n",
       "1             5.392089                      7.000000                125.0   \n",
       "2            33.780445                      0.000000                180.0   \n",
       "3            37.340085                     28.666667                134.0   \n",
       "4            77.794164                     15.000000                114.0   \n",
       "\n",
       "   distance_05  customer  merchant  \n",
       "0    15.856826    168972    152285  \n",
       "1     6.998555    212404     39032  \n",
       "2     1.753009    225178      7439  \n",
       "3     9.000063    183948    485069  \n",
       "4     1.767939    210107    536004  \n",
       "\n",
       "[5 rows x 71 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value counts for column 'activation':\n",
      "activation\n",
      "0    12159962\n",
      "1       70016\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "size = df.shape\n",
    "valid_counts = df.count()\n",
    "\n",
    "column_of_interest = 'activation'\n",
    "\n",
    "# Get the unique values and the number of unique values\n",
    "unique_values = df[column_of_interest].unique()\n",
    "value_counts = df[column_of_interest].value_counts()\n",
    "\n",
    "print(\"Value counts for column '{}':\\n{}\".format(column_of_interest, value_counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop rows\n",
    "major issue of missing values in multiple entires. if eliminate all NA values, the data will have small size\\\n",
    "drop rows with more than half the features being NA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dropping those with more than half the data dimension being na, the size is: (7822511, 71)\n"
     ]
    }
   ],
   "source": [
    "drop_na  = df.dropna(thresh=len(df.columns)/2)\n",
    "del df # save memories\n",
    "print ('After dropping those with more than half the data dimension being na, the size is:', drop_na.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop columns\n",
    "customer_merchant_01, customer_merchant_02, customer_digital_activity_01, 02, 07, 08, 09, 18\\\n",
    "Assumption: they do not contribute significantly to the recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = drop_na.activation\n",
    "columns_to_drop = []\n",
    "for col in drop_na.columns:\n",
    "    if drop_na[col].count() < size[0]*0.1:\n",
    "        columns_to_drop.append(col)\n",
    "\n",
    "data_train = drop_na.drop(columns_to_drop, axis=1)\n",
    "\n",
    "\n",
    "del drop_na\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data_train.drop(['ind_recommended', 'activation', \n",
    "                           #'customer', 'merchant'\n",
    "                           ],axis=1)\n",
    "\n",
    "del data_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Serialize for generation of results (without imputation and undersampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imbalanced UnderSampling: \n",
    "Choice of undersampling technique: Random Undersampling\\\n",
    "https://imbalanced-learn.org/stable/under_sampling.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((134120, 61),\n",
       " activation\n",
       " 0    67060\n",
       " 1    67060\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#   EditedN\n",
    "##  enn = EditedNearestNeighbours()\n",
    "#   X_resampled, y_resampled = enn.fit_resample(X_train, y_train)\n",
    "\n",
    "##  renn = RepeatedEditedNearestNeighbours()\n",
    "#   X_resampled, y_resampled = renn.fit_resample(X_train, y_train)\n",
    "rus = RandomUnderSampler()\n",
    "X_resampled, y_resampled = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "class_count = y_resampled.value_counts()\n",
    "X_resampled.shape, class_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_imputer = KNNImputer(n_neighbors=5)  # Set the number of neighbors as per your dataset\n",
    "X_imputed = knn_imputer.fit_transform(X_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_imputed, y_resampled, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaN values in the array:  0\n"
     ]
    }
   ],
   "source": [
    "nan_count = np.isnan(X_imputed).sum()\n",
    "print(\"Number of NaN values in the array: \", nan_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Serialize for training data use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = ['customer_digital_activity_04',\n",
    "          'customer_spend_01',\n",
    "          'customer_industry_spend_01',\n",
    "          'customer_industry_spend_02',\n",
    "          'customer_industry_spend_03',\n",
    "          'customer_industry_spend_04',\n",
    "          'customer_industry_spend_05',\n",
    "          'customer_spend_02',\n",
    "          'customer_spend_03',\n",
    "          'customer_spend_04', \n",
    "          'customer_spend_05',\n",
    "          'customer_spend_06', \n",
    "          'customer_spend_07',\n",
    "          'merchant_spend_01',\n",
    "          'merchant_spend_02', \n",
    "          'merchant_spend_03', \n",
    "          'merchant_spend_04', \n",
    "          'merchant_spend_05', \n",
    "          'merchant_spend_06', \n",
    "          'merchant_spend_07',  \n",
    "          'merchant_spend_08', \n",
    "          'merchant_profile_01',\n",
    "          'customer_merchant_03',\n",
    "          'customer_profile_01',\n",
    "           'customer_profile_02',\n",
    "           'customer_digital_activity_05',\n",
    "           'customer_spend_13',\n",
    "           'customer_digital_activity_06',\n",
    "           'customer_spend_14',\n",
    "           'customer_digital_activity_10',\n",
    "           'customer_digital_activity_11',\n",
    "           'customer_digital_activity_12',\n",
    "           'customer_digital_activity_13',\n",
    "           'customer_digital_activity_14',\n",
    "           'customer_digital_activity_15',\n",
    "           'customer_spend_15',\n",
    "           'customer_digital_activity_16',\n",
    "           'customer_spend_16',\n",
    "           'customer_spend_17',\n",
    "           'customer_digital_activity_17',\n",
    "           'customer_digital_activity_03',\n",
    "           'merchant_spend_11',\n",
    "           'customer_digital_activity_19',\n",
    "           'distance_01',\n",
    "           'customer_digital_activity_20',\n",
    "           'distance_02',\n",
    "           'distance_03',\n",
    "           'customer_spend_18',\n",
    "           'customer_spend_19',\n",
    "           'customer_digital_activity_21',\n",
    "           'customer_digital_activity_22',\n",
    "           'distance_04',\n",
    "           'merchant_profile_02',\n",
    "           'merchant_spend_09',\n",
    "           'merchant_profile_03',\n",
    "           'merchant_spend_10',\n",
    "           'customer_profile_03',\n",
    "           'customer_profile_04',\n",
    "           'distance_05'\n",
    "]\n",
    "X_train = pd.DataFrame(X_train, columns = header)\n",
    "X_test = pd.DataFrame(X_test, columns = header)\n",
    "\n",
    "#customer_merchant_01, customer_merchant_02, \n",
    "#customer_digital_activity_01, 02, 07, 08, 09, 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize the train and test data ready for continued use training models \n",
    "data = {'X_train': X_train, 'X_test': X_test, 'y_train': y_train, 'y_test': y_test}\n",
    "with open('amex_training.pickle', 'wb') as file:\n",
    "    pickle.dump(data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data (run this everytime the kernel is restarted)\n",
    "with open('amex_training.pickle', 'rb') as file:\n",
    "    data = pickle.load(file)\n",
    "    X_train = data['X_train']\n",
    "    X_test = data['X_test']\n",
    "    y_train = data['y_train']\n",
    "    y_test = data['y_test']\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming X_resampled is the undersampled feature matrix\n",
    "\n",
    "# Define the parameter grid for number of neighbors\n",
    "param_grid = {'n_neighbors': [3, 5, 7, 9, 11]}  \n",
    "\n",
    "# Instantiate the KNNImputer\n",
    "knn_imputer = KNNImputer()\n",
    "\n",
    "# Perform grid search to find the optimal number of neighbors\n",
    "grid_search = GridSearchCV(knn_imputer, param_grid, scoring='roc_auc', cv=5)\n",
    "grid_search.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Best number of neighbors\n",
    "best_neighbors = grid_search.best_params_['n_neighbors']\n",
    "print(f\"Optimal number of neighbors: {best_neighbors}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Standardscaler for distance-based algorithm\n",
    "def scale_features(X_train, X_test):\n",
    "    sc = StandardScaler()\n",
    "    X_train_ss = sc.fit_transform(X_train)\n",
    "    X_test_ss = sc.transform(X_test)\n",
    "    return X_train_ss, X_test_ss\n",
    "X_train_ss, X_test_ss = scale_features(X_train, X_test)\n",
    "\n",
    "X_train_ss = pd.DataFrame(X_train_ss, columns = header)\n",
    "X_test_ss = pd.DataFrame(X_test_ss, columns = header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ZhanX\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\ZhanX\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\ZhanX\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\ZhanX\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\ZhanX\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\ZhanX\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8161630505467493,\n",
       " array([[10963,  2539],\n",
       "        [ 2393, 10929]], dtype=int64))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## RandomForest Classifier\n",
    "RF = RandomForestClassifier(random_state=42)\n",
    "RF.fit(X_train, y_train)\n",
    "y_pred_test_rf = cross_val_predict(RF, X_test, y_test, cv=5, method='predict')\n",
    "roc_auc_score(y_test, y_pred_test_rf), confusion_matrix(y_test, y_pred_test_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7036878454522221,\n",
       " array([[9597, 3905],\n",
       "        [4042, 9280]], dtype=int64))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVC: non standardized\n",
    "svm = SVC(random_state=42)\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred_test_svm = cross_val_predict(svm, X_test, y_test, cv=5, method = \"predict\")\n",
    "roc_auc_score(y_test, y_pred_test_svm), confusion_matrix(y_test, y_pred_test_svm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ZhanX\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\ZhanX\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\ZhanX\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\ZhanX\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\ZhanX\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\ZhanX\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8009846289654308,\n",
       " array([[10694,  2808],\n",
       "        [ 2532, 10790]], dtype=int64))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVC: distanced based so we use X_train_ss\n",
    "svm = SVC(random_state=42)\n",
    "svm.fit(X_train_ss, y_train)\n",
    "y_pred_test_svm = cross_val_predict(svm, X_test_ss, y_test, cv=5, method = \"predict\")\n",
    "roc_auc_score(y_test, y_pred_test_svm), confusion_matrix(y_test, y_pred_test_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.654216762295648,\n",
       " array([[9155, 4347],\n",
       "        [4924, 8398]], dtype=int64))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# KNN Classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5) \n",
    "knn.fit(X_train, y_train)  \n",
    "y_pred_test_knn = cross_val_predict(knn, X_test, y_test, cv=5, method='predict')\n",
    "roc_auc_score(y_test, y_pred_test_knn), confusion_matrix(y_test, y_pred_test_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ZhanX\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\ZhanX\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\ZhanX\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\ZhanX\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\ZhanX\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\ZhanX\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7315345265368616,\n",
       " array([[9751, 3751],\n",
       "        [3452, 9870]], dtype=int64))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# KNN Classifier: Standardized\n",
    "knn = KNeighborsClassifier(n_neighbors=5) \n",
    "knn.fit(X_train_ss, y_train)  \n",
    "y_pred_test_knn = cross_val_predict(knn, X_test_ss, y_test, cv=5, method='predict')\n",
    "roc_auc_score(y_test, y_pred_test_knn), confusion_matrix(y_test, y_pred_test_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensemble: Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ZhanX\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\ZhanX\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf = 0.8215404115717269\n",
      "svc = 0.8095735162541008\n",
      "knn = 0.7458246346555324\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8136743215031316"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Voting Classifier with all exisiting classifier - hard voting\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        #('lr', LogisticRegression(random_state=42)),\n",
    "        ('rf', RandomForestClassifier(random_state=42)),\n",
    "        ('svc', SVC(random_state=42)),\n",
    "        ('knn', KNeighborsClassifier(n_neighbors=5))\n",
    "    ]\n",
    ")\n",
    "voting_clf.fit(X_train_ss, y_train)\n",
    "\n",
    "for name, clf in voting_clf.named_estimators_.items():\n",
    "    print (name, \"=\", clf.score(X_test_ss, y_test))\n",
    "voting_clf.score(X_test_ss, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ZhanX\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\ZhanX\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.81080375782881"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Soft voting\n",
    "voting_clf.voting = \"soft\"\n",
    "voting_clf.named_estimators[\"svc\"].probability = True\n",
    "voting_clf.fit(X_train_ss, y_train)\n",
    "voting_clf.score(X_test_ss, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForest GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset and split into features and target variable\n",
    "# Assuming X and y are the features and target variable\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, 30, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "# Instantiate the Random Forest Classifier\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Perform Grid Search\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Retrieve the Best Parameters\n",
    "best_params = grid_search.best_params_\n",
    "best_estimator = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the Model\n",
    "y_pred = best_estimator.predict(X_test)\n",
    "# Additional evaluation metrics and analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'criterion': 'gini',\n",
       "  'max_depth': None,\n",
       "  'min_samples_split': 5,\n",
       "  'n_estimators': 300},\n",
       " RandomForestClassifier(min_samples_split=5, n_estimators=300))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params, best_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize the best y, estimator, params ready for continued use training models \n",
    "params = {'y_pred': y_pred, 'best_estimator': best_estimator, 'best_params': best_params}\n",
    "with open('amex_GridsearchRF.pickle', 'wb') as file:\n",
    "    pickle.dump(params, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.823046399171187,\n",
       " array([[10933,  2569],\n",
       "        [ 2180, 11142]], dtype=int64))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RF: Best y, parameter, and estimator\n",
    "roc_auc_score(y_test, y_pred), confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVC GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': [1, 0.1, 0.01, 0.001],\n",
    "    'kernel': ['rbf', 'linear', 'poly', 'sigmoid']\n",
    "}\n",
    "\n",
    "# Instantiate the Support Vector Classifier (SVC)\n",
    "svc = SVC()\n",
    "\n",
    "# Perform Grid Search\n",
    "grid_search = GridSearchCV(estimator=svc, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train_ss, y_train)\n",
    "\n",
    "# Retrieve the Best Parameters\n",
    "best_params_svc = grid_search.best_params_\n",
    "best_estimator_svc = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the Model\n",
    "y_pred_svc = best_estimator_svc.predict(X_test_ss)\n",
    "# Additional evaluation metrics and analysis\n",
    "roc_auc_score(y_test, y_pred_svc), confusion_matrix(y_test, y_pred_svc), best_params_svc, best_estimator_svc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLP Neural Network "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Non-Standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ZhanX\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1101: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8118475991649269"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "mlp_clf = MLPClassifier(hidden_layer_sizes=[5], max_iter=10_000,\n",
    "                        random_state=42)\n",
    "pipeline = make_pipeline(StandardScaler(), mlp_clf)\n",
    "pipeline.fit(X_train, y_train)\n",
    "accuracy = pipeline.score(X_test, y_test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ZhanX\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1101: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8118475991649269"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_clf = MLPClassifier(hidden_layer_sizes=[5], max_iter=10_000,\n",
    "                        random_state=42)\n",
    "pipeline = make_pipeline(StandardScaler(), mlp_clf)\n",
    "pipeline.fit(X_train_ss, y_train)\n",
    "accuracy = pipeline.score(X_test_ss, y_test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Keras Tuner network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "\n",
    "def build_model(hp):\n",
    "    n_hidden = hp.Int(\"n_hidden\", min_value=0, max_value=30, default=2)\n",
    "    n_neurons = hp.Int(\"n_neurons\", min_value=16, max_value=800)\n",
    "    learning_rate = hp.Float(\"learning_rate\", min_value=1e-4, max_value=1e-2,\n",
    "                             sampling=\"log\")\n",
    "    optimizer = hp.Choice(\"optimizer\", values=[\"sgd\", \"adam\"])\n",
    "    if optimizer == \"sgd\":\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    else:\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    for _ in range(n_hidden):\n",
    "        model.add(tf.keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=optimizer,\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search_tuner = kt.RandomSearch(\n",
    "    build_model, objective=\"val_accuracy\", max_trials=5, overwrite=True,\n",
    "    directory=\"Amex Hackathon\", project_name=\"recommendation\", seed=42)\n",
    "random_search_tuner.search(X_train_ss, y_train, epochs=100,\n",
    "                           validation_data=(X_test_ss, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top3_models = random_search_tuner.get_best_models(num_models=3)\n",
    "best_model = top3_models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top3_params = random_search_tuner.get_best_hyperparameters(num_trials=3)\n",
    "top3_params[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_trial = random_search_tuner.oracle.get_best_trials(num_trials=1)[0]\n",
    "best_trial.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = tf.keras.layers.Normalization()\n",
    "hidden_layer1 = tf.keras.layers.Dense(30, activation=\"relu\")\n",
    "hidden_layer2 = tf.keras.layers.Dense(30, activation=\"relu\")\n",
    "concat_layer = tf.keras.layers.Concatenate()\n",
    "output_layer = tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "\n",
    "input_ = tf.keras.layers.Input(shape=X_train.shape[1:])\n",
    "normalized = normalization_layer(input_)\n",
    "hidden1 = hidden_layer1(normalized)\n",
    "hidden2 = hidden_layer2(hidden1)\n",
    "concat = concat_layer([normalized, hidden2])\n",
    "output = output_layer(concat)\n",
    "\n",
    "model_xxx = tf.keras.Model(inputs=[input_], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m3353/3353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6779 - loss: 3.0317\n",
      "Epoch 2/20\n",
      "\u001b[1m3353/3353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.7195 - loss: 1.5214\n",
      "Epoch 3/20\n",
      "\u001b[1m3353/3353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.7275 - loss: 0.9006\n",
      "Epoch 4/20\n",
      "\u001b[1m3353/3353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7007 - loss: 1.0449\n",
      "Epoch 5/20\n",
      "\u001b[1m3353/3353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.6791 - loss: 1.0379\n",
      "Epoch 6/20\n",
      "\u001b[1m3353/3353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.7388 - loss: 0.7347\n",
      "Epoch 7/20\n",
      "\u001b[1m3353/3353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7497 - loss: 0.6611\n",
      "Epoch 8/20\n",
      "\u001b[1m3353/3353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7661 - loss: 0.6374\n",
      "Epoch 9/20\n",
      "\u001b[1m3353/3353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7717 - loss: 0.5894\n",
      "Epoch 10/20\n",
      "\u001b[1m3353/3353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.7499 - loss: 0.6764\n",
      "Epoch 11/20\n",
      "\u001b[1m3353/3353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7622 - loss: 0.6217\n",
      "Epoch 12/20\n",
      "\u001b[1m3353/3353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.7807 - loss: 0.5651\n",
      "Epoch 13/20\n",
      "\u001b[1m3353/3353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7775 - loss: 0.5731\n",
      "Epoch 14/20\n",
      "\u001b[1m3353/3353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7722 - loss: 0.6062\n",
      "Epoch 15/20\n",
      "\u001b[1m3353/3353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7842 - loss: 0.5530\n",
      "Epoch 16/20\n",
      "\u001b[1m3353/3353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.7757 - loss: 0.6066\n",
      "Epoch 17/20\n",
      "\u001b[1m3353/3353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.7581 - loss: 0.7045\n",
      "Epoch 18/20\n",
      "\u001b[1m3353/3353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step - accuracy: 0.7929 - loss: 0.5768\n",
      "Epoch 19/20\n",
      "\u001b[1m3353/3353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.7799 - loss: 0.5850\n",
      "Epoch 20/20\n",
      "\u001b[1m3353/3353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.7913 - loss: 0.5333\n",
      "\u001b[1m839/839\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7591 - loss: 0.5956\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "model_xxx.compile(loss=\"binary_crossentropy\", optimizer=optimizer,\n",
    "                  metrics=[\"accuracy\"])\n",
    "normalization_layer.adapt(X_train)\n",
    "history = model_xxx.fit(X_train, y_train, epochs=20)\n",
    "score = model_xxx.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"amex_eval_round1_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['customer_merchant_01', 'customer_merchant_02',\n",
    "                   'customer_digital_activity_01', \n",
    "                   'customer_digital_activity_02', \n",
    "                   'customer_digital_activity_07', \n",
    "                   'customer_digital_activity_08',\n",
    "                   'customer_digital_activity_09',\n",
    "                   'customer_digital_activity_18'\n",
    "                   ]\n",
    "\n",
    "df_test = df_test.drop(columns_to_drop, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_ID = df_test['customer']\n",
    "merchant_ID = df_test['merchant']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Customer_ID': customer_ID, 'Merchant_ID': merchant_ID}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Write the DataFrame to a new CSV file with headers\n",
    "df.to_csv('output.csv', index=False)\n",
    "del customer_ID, merchant_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_test.drop(['customer', 'merchant'],axis=1)\n",
    "\n",
    "del df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_imputer = KNNImputer(n_neighbors=5)  # Set the number of neighbors as per your dataset\n",
    "\n",
    "X = knn_imputer.fit_transform(X)\n",
    "\n",
    "nan_count = np.isnan(X).sum()\n",
    "print(\"Number of NaN values in the array: \", nan_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize the train and test data ready for continued use training models \n",
    "data = {'X': X}\n",
    "with open('amex_submission.pickle', 'wb') as file:\n",
    "    pickle.dump(data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data (run this everytime the kernel is restarted)\n",
    "with open('amex_submission.pickle', 'rb') as file:\n",
    "    data = pickle.load(file)\n",
    "    X = data['X']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['distance_05', 'customer_digital_activity_04', 'customer_spend_01',\n",
       "       'customer_industry_spend_01', 'customer_industry_spend_02',\n",
       "       'customer_industry_spend_03', 'customer_industry_spend_04',\n",
       "       'customer_industry_spend_05', 'customer_spend_02', 'customer_spend_03',\n",
       "       'customer_spend_04', 'customer_spend_05', 'customer_spend_06',\n",
       "       'customer_spend_07', 'merchant_spend_01', 'merchant_spend_02',\n",
       "       'merchant_spend_03', 'merchant_spend_04', 'merchant_spend_05',\n",
       "       'merchant_spend_06', 'merchant_spend_07', 'merchant_spend_08',\n",
       "       'merchant_profile_01', 'customer_merchant_03', 'customer_profile_01',\n",
       "       'customer_profile_02', 'customer_digital_activity_05',\n",
       "       'customer_spend_13', 'customer_digital_activity_06',\n",
       "       'customer_spend_14', 'customer_digital_activity_10',\n",
       "       'customer_digital_activity_11', 'customer_digital_activity_12',\n",
       "       'customer_digital_activity_13', 'customer_digital_activity_14',\n",
       "       'customer_digital_activity_15', 'customer_spend_15',\n",
       "       'customer_digital_activity_16', 'customer_spend_16',\n",
       "       'customer_spend_17', 'customer_digital_activity_17',\n",
       "       'customer_digital_activity_03', 'merchant_spend_11',\n",
       "       'customer_digital_activity_19', 'distance_01',\n",
       "       'customer_digital_activity_20', 'distance_02', 'distance_03',\n",
       "       'customer_spend_18', 'customer_spend_19',\n",
       "       'customer_digital_activity_21', 'customer_digital_activity_22',\n",
       "       'distance_04', 'merchant_profile_02', 'merchant_spend_09',\n",
       "       'merchant_profile_03', 'customer_digital_activity_01',\n",
       "       'merchant_spend_10', 'customer_profile_03',\n",
       "       'customer_digital_activity_02', 'customer_profile_04'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of           distance_05  customer_digital_activity_04  customer_spend_01  \\\n",
       "0            1.621171                           NaN         112.334000   \n",
       "1            2.441944                           NaN         112.334000   \n",
       "2            2.438082                           NaN         112.334000   \n",
       "3            2.072182                           NaN         112.334000   \n",
       "4            2.380853                           NaN         302.792500   \n",
       "...               ...                           ...                ...   \n",
       "12604595    17.082029                           NaN         631.800000   \n",
       "12604596    25.099151                           NaN          49.490000   \n",
       "12604597     8.815975                           NaN         494.520000   \n",
       "12604598    16.690912                           NaN          78.063171   \n",
       "12604599    24.558746                           NaN          85.592927   \n",
       "\n",
       "          customer_industry_spend_01  customer_industry_spend_02  \\\n",
       "0                          80.552500                         9.0   \n",
       "1                                NaN                         NaN   \n",
       "2                          71.192500                         3.0   \n",
       "3                                NaN                         NaN   \n",
       "4                                NaN                         NaN   \n",
       "...                              ...                         ...   \n",
       "12604595                         NaN                         NaN   \n",
       "12604596                         NaN                         NaN   \n",
       "12604597                         NaN                         NaN   \n",
       "12604598                   62.619464                         3.0   \n",
       "12604599                   64.952632                         3.0   \n",
       "\n",
       "          customer_industry_spend_03  customer_industry_spend_04  \\\n",
       "0                             966.63                        12.0   \n",
       "1                                NaN                         NaN   \n",
       "2                             284.77                         4.0   \n",
       "3                                NaN                         NaN   \n",
       "4                                NaN                         NaN   \n",
       "...                              ...                         ...   \n",
       "12604595                         NaN                         NaN   \n",
       "12604596                         NaN                         NaN   \n",
       "12604597                         NaN                         NaN   \n",
       "12604598                     3506.69                        56.0   \n",
       "12604599                     3702.30                        57.0   \n",
       "\n",
       "          customer_industry_spend_05  customer_spend_02  customer_spend_03  \\\n",
       "0                               10.0                4.0               41.0   \n",
       "1                                NaN                4.0               41.0   \n",
       "2                                4.0                4.0               41.0   \n",
       "3                                NaN                4.0               41.0   \n",
       "4                                NaN                3.0               37.0   \n",
       "...                              ...                ...                ...   \n",
       "12604595                         NaN                1.0                1.0   \n",
       "12604596                         NaN                2.0                9.0   \n",
       "12604597                         NaN                7.0               26.0   \n",
       "12604598                        54.0               13.0               63.0   \n",
       "12604599                        55.0               13.0               63.0   \n",
       "\n",
       "          ...  customer_spend_19  customer_digital_activity_21  \\\n",
       "0         ...             56.985                           NaN   \n",
       "1         ...             53.270                           0.0   \n",
       "2         ...             61.000                           0.0   \n",
       "3         ...                NaN                           NaN   \n",
       "4         ...                NaN                           0.0   \n",
       "...       ...                ...                           ...   \n",
       "12604595  ...                NaN                           NaN   \n",
       "12604596  ...                NaN                           NaN   \n",
       "12604597  ...                NaN                           NaN   \n",
       "12604598  ...             44.795                           0.0   \n",
       "12604599  ...             44.795                           NaN   \n",
       "\n",
       "          customer_digital_activity_22  distance_04  merchant_profile_02  \\\n",
       "0                                  NaN          NaN             0.437500   \n",
       "1                             0.000183     5.500000             0.397059   \n",
       "2                             0.000000     5.500000                  NaN   \n",
       "3                                  NaN          NaN             0.142857   \n",
       "4                             0.000000    10.000000             0.100000   \n",
       "...                                ...          ...                  ...   \n",
       "12604595                           NaN    14.476923             0.061770   \n",
       "12604596                           NaN          NaN                  NaN   \n",
       "12604597                           NaN          NaN                  NaN   \n",
       "12604598                           NaN   156.000000             0.080000   \n",
       "12604599                           NaN   117.500000             0.272727   \n",
       "\n",
       "          merchant_spend_09  merchant_profile_03  merchant_spend_10  \\\n",
       "0                   26299.0               4777.0             33.300   \n",
       "1                    7122.0               4803.0            793.290   \n",
       "2                    7222.0              14860.0            100.000   \n",
       "3                   11410.0              11968.0            252.380   \n",
       "4                    1847.0               5842.0             87.500   \n",
       "...                     ...                  ...                ...   \n",
       "12604595            44184.0              40128.0             29.630   \n",
       "12604596                NaN                  NaN                NaN   \n",
       "12604597                NaN                  NaN                NaN   \n",
       "12604598            10777.0              17744.0             21.965   \n",
       "12604599             9090.0               3607.0             24.250   \n",
       "\n",
       "          customer_profile_03  customer_profile_04  \n",
       "0                   72.268283                423.0  \n",
       "1                   72.268283                423.0  \n",
       "2                   72.268283                423.0  \n",
       "3                   72.268283                423.0  \n",
       "4                   72.268283                423.0  \n",
       "...                       ...                  ...  \n",
       "12604595             0.924042                182.0  \n",
       "12604596            15.819092                536.0  \n",
       "12604597            40.522384                 62.0  \n",
       "12604598            96.337732                 49.0  \n",
       "12604599            96.337732                 49.0  \n",
       "\n",
       "[12604600 rows x 59 columns]>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The feature sequence of evaluation data differs from training set, we rearrange\n",
    "column_order = X_train.columns.tolist()\n",
    "\n",
    "# Reorder the columns of X_test to match the order of columns in X_train\n",
    "X = X[column_order]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ZhanX\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "## RandomForest Classifier\n",
    "best_params_rf = {'criterion': 'gini',\n",
    "                    'max_depth': None,\n",
    "                    'min_samples_split': 5,\n",
    "                    'n_estimators': 300}\n",
    "\n",
    "rf_test = RandomForestClassifier(**best_params_rf)\n",
    "rf_test.fit(X_train, y_train)\n",
    "y_pred_test_rf = rf_test.predict(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba_test_rf = rf_test.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.54453175],\n",
       "       [0.61021032],\n",
       "       [0.55177778],\n",
       "       ...,\n",
       "       [0.55161111],\n",
       "       [0.52939562],\n",
       "       [0.49080592]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba_test_rf[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generation of results\n",
    "df_output = pd.read_csv('output.csv')\n",
    "#header_output = ['customer', 'merchant', 'predicted_score']\n",
    "\n",
    "\n",
    "predicted_scores = y_pred_proba_test_rf[:, 1:]\n",
    "df_output['predicted_score'] = predicted_scores\n",
    "\n",
    "# Rename the existing columns\n",
    "df_output.rename(columns={'Customer_ID': 'customer', 'Merchant_ID': 'merchant'}, inplace=True)\n",
    "\n",
    "# Write the modified DataFrame to a new CSV file\n",
    "df_output.to_csv('ZXXX.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
